---
title: "Basic Ordination Methods"
subtitle: "Ordination 101 for Ecological Methods"
author: "Jari Oksanen"
date: "Nov 8 to 15, 2017"
output:
  xaringan::moon_reader:
    css: ['default', './resources/gavins.css']
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9'
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(comment=NA,
                      echo = FALSE, message = FALSE, warning = FALSE, cache = TRUE,
                      fig.align = 'center', fig.height = 5, fig.width = 5.5, dev = 'svg')
knitr::knit_hooks$set(crop.plot = knitr::hook_pdfcrop)
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(rgl.newwindow = TRUE)
```
```{r packages, include = FALSE, cache = FALSE}
require('vegan')
data('varespec', 'varechem', 'mite')
require('labdsv')
data('bryceveg')
library('mgcv')
require('knitr')
require('viridis')
```
<!-- ********** INTRO ************ -->
<!-- ********** PCA ************** -->
---
class: inverse center middle

# PCA: Principal Components Analysis

PCA  is the  basic ordination  method and  the one  that Statisticians
know. It is poor for most uses,  but we need to know PCA to understand
how other methods improve upon it.  The main problem of PCA is that it
is  linear, but  community  data are  nonlinear.
---
# From Regression to Ordination

- What is the best possible predictor variable for a species? --- It
  is the species itself!

- Some species can also be strong in predicting the abundances of
  other species

- The best possible predictor is such a (linear) combination of
  species that explains abundances of all species as well as possible

- That linear combination is the first PCA axis
---
# 3 Cryptogams in Reindeer Pastures

```{r bottpredict, fig.width=8, fig.height=5.5}
bott <- varespec[, c("Pleuschr","Cladrang","Cladstel")]
bott0 <- scale(bott, scale = FALSE)
par(mar=c(4,4,1,1)+.1)
palette(viridis(8))
panel.lm <- function(x, y, col.smooth = 1, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    points(x, y, ...)
    mod <- lm(y ~ x)
    txt <- paste0("Resid.Var = ", round(summary(mod)$sigma^2, 1))
    abline(mod, col = col.smooth, lwd=2)
    text(mean(usr[1:2]), 0.9*usr[4], txt)
}
pairs(bott0, pch=16, col = 4, ylim = range(bott0), panel = panel.lm)
```
---
# Best Predictor
```{r bottpc1, fig.width=10}
mod <- rda(bott0)
koef <- mod$CA$v[,1]
xlab = paste(formatC(koef,digits=2, flag="+"), names(koef), sep="*",collapse="")
PC1 <- (bott0 %*% mod$CA$v)[,1]
df <- data.frame(bott0)
palette(viridis(8))
par(mar=c(4,4,1,1)+.1, mfrow=c(1,3))
ylim <- range(bott0)
plot(Pleuschr ~ PC1, df, type="n", ylim=ylim, xlab=xlab)
panel.lm(PC1, df$Pleuschr, pch=16, col = 2, col.smooth=4)
plot(Cladrang ~ PC1, df, type="n", ylim=ylim, xlab=xlab)
panel.lm(PC1, df$Cladrang, pch=16, col = 2, col.smooth=4)
plot(Cladstel ~ PC1, df, type="n", ylim=ylim, xlab=xlab)
panel.lm(PC1, df$Cladstel, pch=16, col = 2, col.smooth=4)

```
---
# What Was Explained?

- PCA explains the **variance** of the data: the squared
  differences between observed values $y$ and species means $\bar y$:
  $\mathrm{Var}(y_j) = \sum_{i=1}^N(y_{ij} - \bar y_j)^2/(N-1)$
  - NB., ordination always uses centred data so that $\bar y = 0$

- In the example, the variances of three species were
  `r round(apply(bott0, 2, var), 1)`, with sum
  `r round(mod$tot.chi, 1)`, and the sum of residual variances of the PC
  regression was `r round(mod$tot.chi - mod$CA$eig[1], 1)`

- The variance explained by the first PC is the **eigenvalue** of the
  axis, and it is the difference of total variance and residual
  variance $\lambda_1 =$ `r round(mod$CA$eig[1], 1)` which is
  `r round(100*mod$CA$eig[1]/mod$tot.chi, 1)`% of total variance

- The coefficients (`r round(mod$CA$v[,1], 3)`) of three species are
  the **species scores** used in ordination diagrams, and they are also
  regression coefficients that project centred species abundances to
  the PC
  - NB., ordination always uses centred data so that intercept
  is zero

- The result of this projection are the sampling unit **(SU) scores**
  that are used in ordination diagrams -- this is also called as the
  **principal component**

---
# Second and Further Principal Components

- Second PC has similar components, but is **orthogonal** to the
  previous one:

- Species scores and SU scores are orthogonal to (uncorrelated with)
  correspoding scores in the previous axes

- The second PC explains the largest possible amount of remaining
  variance
  - In the example, its eigenvalue is $\lambda_2 =$ `r round(mod$CA$eig[2], 1)`
    which is  `r round(100*mod$CA$eig[2]/mod$tot.chi, 1)`% of total variance

- The sum of all $R$ eigenvalues is equal to the variances of all
   species $\sum_{r=1}^R \lambda_r = \sum_{j=1}^S \mathrm{Var}(y_j)$:
   The axes decompose variance into independent ordered components

- In modern software, we do not find second and further PCs one-by-one
  with orthogonalization, but the interpretation of the results is
  still similar

---
# Is This Circular?

- We explain species by species &mdash; and this sound badly circular

- We perform no statistical testing, and what looks regression
  actually is **rotation** of species data

- We only like to find a way of looking at the data so that some first
  (say PC1 and PC2) so as much of the variance of the data as possible

- Then we can ignore the later axes and say that a **major part** of
  variation in the data is displayed in the first dimensions that we
  can graph

- PCA is **not** a statistical method, but it is only a rotation of
  the data

---
# Species Scores in Multidimensions

.pull-left[

- We had species scores for a single axis, but in 2 and more dimensions
  we must look at all dimensions simultaneously

- The coefficients together define the **direction** to which the
  species abundance **increases** most steeply &mdash; and it
  **decreases** in the opposite direction

- The response is linear in 2D: the contours of linear trend surface are
  perpendicular to the arrow

- The estimated abundances of all species on each SU can be read by
  projecting the SU point to the arrow: PCA **approximates** data

- Species were centred: The zero contour goes through the origin

]

.pull-right[
```{r plot3sp}
par(mar=c(4,4,1,1)+.1)
palette(viridis(8))
biplot(mod, type = c("text","points"))
tmp <- ordisurf(mod ~ Cladstel, df, add = TRUE, col=4, knots=1)
```
]

---
# Distance and Direction From the Origin

.pull-left[

- In the origin, each species occurs at its average abundance $\bar y_j$

- The further away from the origin SU is situated, the more strongly
  species abundances differ from the average

- For species the angles between arrows indicate similar pattern of
  change, and the length of the arrow the steepness of the change

- Try yourself: where these species are most abundant and scarcest?
  Which species attain highest abundances and where? Which species
  replace each other and which are independent from each other?
]

.pull-right[

```{r plot3sp2}
par(mar=c(4,4,1,1)+.1)
palette(viridis(8))
biplot(mod, col=c(4,1))
```

]
---
# Rotation in Species Space

### Please Add Me!
---
# Complete Reindeer Pasture Data

.pull-left[

- Analysis of complete data not too different from just three species

- PCA analyses variances and shows absolute differences from the mean
  $y - \bar y$: minor species change little in absolute units

- Actually only some few species influence results, and the data are
  not very multivariate

]

.pull-right[
```{r pcavare}
par(mar=c(4,4,1,1)+.1)
palette(viridis(8))
modf <- rda(varespec)
biplot(modf, col=c(4,1))
```
]

---
# Explaining Variance

.pull-left[

- Abundant species have high variance, and PCA explains variance

- It may be very easy to explain variance, when only a few species
  account for the most, because then data are not very
  multidimensional

- Minor species may be ecological indicators, but they have little
  effect on community ordination with PCA

- Three abundant cryptogams accounted for
  `r round(100*mod$tot.chi/modf$tot.chi, 1)`% of total variance in the complete
  data set, and are dominant in PCA

]

.pull-right[

```{r varabu}
par(mar=c(4,4,1,1)+.1)
v <- apply(varespec, 2, var)
plot(colMeans(varespec), v, xlab="Mean Abundance", ylab="Variance", type="n")
ordilabel(cbind(colMeans(varespec), v), priority = v, fill = "yellow")
```

]
---
# Equal Weights to All Species

.pull-left[

- Use correlation instead of variance and minimize residual $1-R^2$:
  This gives equal weights to all species

- Equalized data are more multidimensional, and scarce species will
  also influence the result, and they change from the previous

- PCA implies that species effects should be shown by arrows, but this
  makes graphs very messy, and often it makes sense to drop arrows and
  just show the species scores at arrowheads

- They still should be interpreted like arrows: Distance and direction
  from the origin counts

]

.pull-right[
```{r pcacorr}
mod1 <- rda(varespec, scale=TRUE)
palette(viridis(8))
par(mar=c(4,4,1,1)+.1)
plot(mod1, scaling="sites", type="n")
text(mod1, scaling="sites", dis="site", col = 1, cex=0.7)
text(mod1, scaling="sites", dis="species", col=4, cex=0.8)
```
]
---
class:  inverse center middle

## PCA Trouble: It is Linear!
---
# Linear Method

- PCA builds upon idea of linear regression

- PC axis are sometimes called as latent variables: unknown and hidden
  real variables that we dig up from data

- Community response to environmental variables is non-linear: PC axes
  cannot find such variables

```{r mtfgrad, fig.width=10, fig.height=3}
source('data/mtfit.R')
palette(viridis(6))
par(mar=c(4,4,1,1)+.1)
matplot(altfit, mtfit, type="l", lty=1, xlab="Altitude (m)", ylab="Species Response")
```
---
# Horseshoe: Beware!

.pull-left[

- If species have nonlinear, unimodal response to gradients, the
  gradient appears as a curve: **horseshoe artifact**

- People often want to interpret axes as latent variables, but even
  single gradient is not an axis: **Beware**

- Even if you are aware of the risk of horseshoe, it can hide other
  shorter gradients: using two dimensions for one gradient is wasteful
  and confusing

- In general, PCA **should not be used** for community data

- PCA is useful for linear data, or for deriving new combined
  variables for other analyses when PCA explains a large proportion of
  variance

]

.pull-right[
```{r horseshoe}
mod <- rda(mtfit)
palette(viridis(8))
par(mar=c(4,4,1,1)+.1)
plot(mod, dis="si", scaling="si", type="n")
points(mod, dis="si", scaling="si", pch=16)
```
]
---
# Horseshoe is Common

```{r morehorses, fig.width=10}
palette(viridis(8))
par(mfrow=c(1,3), mar=c(4,4,2,1)+.1)
m1 <- rda(varespec)
m2 <- rda(bryceveg)
m3 <- rda(mite)
plot(m1, dis="si", type="n", main="Reindeer Pastures")
points(m1, dis="si", pch=16)
plot(m2, dis="si", type="n", main="Bryce Canyon")
points(m2, dis="si", pch=16)
plot(m3, dis="si", type="n", main="Oribatid Mites")
points(m3, dis="si", pch=16)
```
---
# When Would We Expect a Horseshoe?


- **Always** with community data

- Even when we cannot see the horseshoe, it may be hidden below the
  crumble of noisy analysis

- Horseshoe can hide underlying gradients and disperse their effect
  over several PCs so that they cannot be found and interpreted

---
# Niche for PCA

.pull-left[

- New synthetic variables from correlated measurements to avoid
  problems of collinearity

- For this PCA should explain a large amount of variance

- Use only the subset of correlated variables that may be assumed to
  descrige the same underlying (latent) variable: **measurement
  model**

- Use correlations when variables are not measured in the same units

- Do not use axes directly: they may not be parallel to interpretable
  variables

]

.pull-right[

```{r latent}
mod <- rda(varechem, scale=TRUE)
palette(viridis(8))
par(mar=c(4,4,1,1)+.1)
biplot(mod, display="sp", col=1)
```

]

<!-- ********* CA ************ -->
---
class: inverse center middle

# CA: Correspondence Analysis

Correspondence Analysis is an eigenvector method just like PCA, and it
can be seen as its variant. However, this small difference makes it
handle nonlinear species responses better than PCA. For community
data, CA is usually a much better alternative than PCA.

---
# Correspondence Analysis

- In PCA we explain the differences of species from their average
  $y_{ij} - \bar y_j$, using its mean square (variance) as a measure
  of goodness of fit

- In CA the expected value is derived both from the SU and species,
  and the goodness of fit is $\chi^2$

- We first scale the observed data so that their sum is one
  $\left( \sum_{i=1}^N \sum_{j=1}^S y_{ij} = 1 \right)$
  &mdash; that is, we divide data with its sum

- If all communities have identical species composition, and all
  species occur in equal proportion in all SUs, then the expected
  abundance is $r_i c_j$ where $r_i$ is row (SU) sum and $c_j$ is the
  column (species) sum: This takes the place of $\bar y_j$ of PCA

- We look at proportional difference
  $(y_{ij} - r_i c_j)/\sqrt{r_i c_j}$, and its square is
  $\chi^2 = (y_{ij} - r_i c_j)^2/(r_i c_j)$:
  This takes the place of variance of PCA

- Then we proceed with regression to find the axes, just like in PCA
  (except that we need to use weights $\sqrt{r_i}$, $\sqrt{c_j}$)

---
# The Small but Important Difference

```{r cagam}
palette(viridis(3))
par(mar=c(4,4,1,1)+.1)
mod <- cca(bott) # from PCA lecture
CA1 <- mod$CA$u[,1]
matplot(CA1, bott, pch=16, xlab = "CA axis 1", ylab="Species Abundance")
legend("top", colnames(bott), pch=16, lty=1, col=1:3, bty="n")
i <- order(CA1)
for(k in 1:3) {
   m <- gam(bott[,k] ~ s(CA1, k=4), family=quasipoisson)
   lines(CA1[i], fitted(m)[i], lwd=2, col = k)
}
```
---
# PCA Orders Linearly, CA Packs

---
class: inverse center middle

# Interpretation: Ordination and External Variables
---

class: inverse center middle

# PCoA: Principal Coordinates Analysis
---
class: inverse center middle

# NMDS: Nonmetric Multidimensional Scaling
---
